{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn import ensemble\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i heartily appreciate a director who has made ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i know i knowðŸ˜’</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i'm very proud to be talking about the emotion...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>choosing to ignore &amp; not speak on things that ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>waiting for the day loona does a soshi cover s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  class\n",
       "0  i heartily appreciate a director who has made ...      1\n",
       "1                                     i know i knowðŸ˜’      0\n",
       "2  i'm very proud to be talking about the emotion...      1\n",
       "3  choosing to ignore & not speak on things that ...      0\n",
       "4  waiting for the day loona does a soshi cover s...      0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"shuffled_data.csv\")\n",
    "\n",
    "tweets = list(df[\"tweet\"])\n",
    "labels = list(df[\"class\"])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(texts):\n",
    "    new_texts = []\n",
    "    for text in texts:\n",
    "        text = text.lower()\n",
    "        # special characters\n",
    "        text = re.sub(r'\\W', ' ', text)\n",
    "        # single characters\n",
    "        text = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', text)\n",
    "        # substitute multiple spaces with single one\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        # single characters from the start\n",
    "        text = re.sub(r'\\^[a-zA-Z]\\s+', ' ', text)\n",
    "        # lemmatization\n",
    "        text = text.split(' ')\n",
    "        text = [stemmer.lemmatize(word) for word in text]\n",
    "        new_texts.append(' '.join(text))\n",
    "    return new_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "stemmer = WordNetLemmatizer()\n",
    "tweets_processed = process_text(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i heartily appreciate director who ha made or want to make film about mental health and severity of clinical depression bipolar adhd ocd etc generally people assume reason for these is just lack of will power  \n",
      " i heartily appreciate a director who has made or wants to make a film about mental health and severity of clinical depression,bipolar,adhd,ocd,etc. generally people assume reason for these is just lack of will power.\n"
     ]
    }
   ],
   "source": [
    "print(tweets_processed[0], '\\n', tweets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vect = CountVectorizer(stop_words=stopwords.words('english'))\n",
    "X = vect.fit_transform(tweets_processed).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfd = TfidfTransformer()\n",
    "X = tfd.fit_transform(X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn import ensemble\n",
    "\n",
    "models = [\n",
    "          KNeighborsRegressor(),\n",
    "          linear_model.Lasso(),\n",
    "          linear_model.Ridge(),\n",
    "          linear_model.ElasticNet(),\n",
    "          ensemble.GradientBoostingRegressor(),\n",
    "          ensemble.RandomForestRegressor(),\n",
    "          ensemble.ExtraTreesRegressor()\n",
    "]\n",
    "\n",
    "models_names = ['K-nn','Lasso','Ridge','Elastic','Boost','Forest','Extra']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "scores, mse, mae = [], [], []\n",
    "\n",
    "for model in models:\n",
    "    fits = model.fit(x_train, y_train)\n",
    "    scores.append(metrics.r2_score(y_test, fits.predict(x_test)))\n",
    "    mse.append(metrics.mean_squared_error(y_test, fits.predict(x_test)))    \n",
    "    mae.append(metrics.mean_absolute_error(y_test, fits.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize = (18, 6))\n",
    "plt.title(\"Scoring metrics\")\n",
    "ax1.set_title(\"R^2\")\n",
    "ax1.bar(models_names, scores)\n",
    "ax1.set_title(\"MSE\")\n",
    "ax2.bar(models_names, mse)\n",
    "ax1.set_title(\"MAE\")\n",
    "ax3.bar(models_names, mae)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
